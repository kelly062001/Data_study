{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지도학습 - 분류\n",
    "#### 자주 사용하는 사이킷런 모듈\n",
    "- sklearn.ensemble: 앙상블 알고리즘(RF, AdaBoost 등)\n",
    "- sklearn.linear_model: 선형모델(선형회귀, 로지스틱회귀 등) \n",
    "- sklearn.svm: Support Vector Machines (SVM)\n",
    "- sklearn.tree: 의사결정나무(Decision Trees)\n",
    "- sklearn.neighbors : K-최근접이웃모델 (KNeighbors)\n",
    "\n",
    "#### 사이킷런 기반 머신러닝 프레임워크    \n",
    "- 사이킷런에서는 분류 알고리즘을 구현한 클래스를 **Classifier**로, 회귀 알고리즘을 구현한 클래스를 **Regressor**로 지칭\n",
    "    - Ex) DecisionTreeClassifier(분류문제에 사용하는 의사결정나무) vs. DecisionTreeRegressor(회귀문제에 사용하는 의사결정나무)\n",
    "- Classifier와 Regressor를 합쳐서 **Estimator** 클래스라고 함\n",
    "    - ML 학습을 위해 fit()을, 예측을 위해 predict()를 제공  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 모델 알고리즘\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 데이터 셋\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 정규화, 표준화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# 검증\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load\n",
    "- iris data\n",
    "    - 꽃의 특성 (feature) 데이터 \n",
    "        - [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’]    \n",
    "            - sepal: 꽃받침 / petal: 꽃잎\n",
    "    - target(y)는 세 가지의 꽃의 종류\n",
    "        - 0: Setosa, 1: Versicolor, 2: Virginica\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris_data.data, columns = iris_data.feature_names)\n",
    "iris_df['target'] = iris_data.target\n",
    "\n",
    "iris_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data & target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iris_df.iloc[:,:-1]\n",
    "target = iris_df['target']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train & test data 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 의사결정나무 (Decision Tree) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 객체화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state = 111, criterion = 'entropy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 내가 설정한 대로 성능이 바뀌는 것을 하이퍼 파라미터라고 한다. (max_depth , n_estimators ... ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 머신러닝의 3단계\n",
    "    - 1) 모델의 객체화 \n",
    "    - 2) 모델 학습\n",
    "    - 3) 모델 적용 (예측 & 분류)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn에서 제공하는 Decision Tree 순수도의 척도는 엔트로피 외에도 지니 지수가 있다. (기본값이 gini이기에 criterion을 정해주지 않으면 지니 지수로 순수도를 계산하게 된다.) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- criterion 외에도 의사결정나무에는 수 많은 하이퍼 파라미터가 존재한다. 하이퍼 파라미터를 튜닝하는 것 자체로도 성능이 향상될 수 있다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "pred = dt.predict(X_test)\n",
    "accuracy_score(pred, y_test)\n",
    "# dt.score(X = X_test, y = y_test)\n",
    "# print(classification_report(y_test, pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_tree(dt, filled=True, class_names=['Setosa', 'Versicolor', 'Virginica'], feature_names=X_train.columns)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- plottree : decision tree를 graph로 시각화 해주는 패키지 \n",
    "    - filled :  그래프의 class별로 색의 차이를 둠. (엔트로피 별 농도 차이 존재) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  마지막 노드에서 entropy 0.0을 출력한다. 이는 완벽하게 분리시켰다고 말할 수 도 있지만, 사실 억지로 분류시킨 것에 가깝다. 그렇기에 과적합(Overfitting)발생 의심. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가지치기 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_depth를 이용하여 최대 깊이를 조절한다. (가지치기) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pruning = DecisionTreeClassifier(random_state= 2022, max_depth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pruning.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_pruning.score(X = X_test, y = y_test)\n",
    "pred = dt_pruning.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plot_tree(dt_pruning, filled=True, class_names=['Setosa', 'Versicolor', 'Virginica'], feature_names=X_train.columns)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- depth가 1일 경우 정확도가 확 낮아진다. 이처럼 depth가 무조건 작다고 좋은 것은 아님. 최적의 depth를 구해내야함. \n",
    "\n",
    "- iris 데이터셋의 경우 데이터의 양도 적고 애초에 depth가 깊지 않기 때문에 정확도의 차이가 발생하지 않는다. \n",
    "\n",
    "- iris 데이터 외에도 다른 데이터 셋을 이용하여 max_depth를 조절해보길 바란다. \n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분류 : SVC\n",
    "- 회귀 : SVR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = iris_df.iloc[:, :2]\n",
    "y_train = iris_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2, random_state = 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2차원"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### kernel = 'linear'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### C = 0.1, 1, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_01 = svm.SVC(kernel = 'linear', C = 0.1)\n",
    "svm_01.fit(X_train, y_train)\n",
    "pred = svm_01.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_1 = svm.SVC(kernel = 'linear', C= 1)\n",
    "svm_1.fit(X_train, y_train)\n",
    "pred = svm_1.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_1000 = svm.SVC(kernel = 'linear', C= 1000)\n",
    "svm_1000.fit(X_train, y_train)\n",
    "pred = svm_1000.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max=X_train.iloc[:,0].min()-1, X_train.iloc[:,0].max()+1\n",
    "y_min, y_max=X_train.iloc[:,1].min()-1,X_train.iloc[:,1].max()+1\n",
    "plot_unit=0.025\n",
    "xx,yy=np.meshgrid(np.arange(x_min, x_max, plot_unit), np.arange(y_min, y_max, plot_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xx,yy)\n",
    "print(xx.shape, yy.shape)\n",
    "# 격자의 좌표 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- meshgrid : 직사각형의 그리드 (격자) 안에 배치 될 수 있도록 하는 함수\n",
    "- x_min-1 ~ x_max+1 / y_min-1 ~ y_max+1 사이에서 0.25 간격마다 그리드(격자) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,15))\n",
    "z_1=svm_1.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z_1=z_1.reshape(xx.shape)\n",
    "\n",
    "ax1 = plt.subplot(3,1,1)\n",
    "plt.pcolormesh(xx,yy,z_1,alpha=0.5)\n",
    "# plt.pcolormesh() : 2D스타일의 색상 플롯 생성, alpha = 색상의 농도\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,15))\n",
    "\n",
    "# C = 0.1\n",
    "\n",
    "# 초평면을 만드는 과정\n",
    "# np.c_[] : 같은 크기의 두 배열을 가로방향(왼쪽 -> 오른쪽)으로 합쳐줌\n",
    "z_01=svm_01.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z_01=z_01.reshape(xx.shape)\n",
    "\n",
    "ax1 = plt.subplot(3,1,1)\n",
    "plt.pcolormesh(xx,yy,z_01,alpha=0.1)\n",
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('Support Vector Machine_C=0.1')\n",
    "\n",
    "# C = 1\n",
    "z_1=svm_1.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z_1=z_1.reshape(xx.shape)\n",
    "ax2 = plt.subplot(3,1,2, sharex = ax1)\n",
    "plt.pcolormesh(xx,yy,z_1,alpha=0.1)\n",
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('Support Vector Machine_C=1')\n",
    "\n",
    "# C = 1000\n",
    "z_1000=svm_1000.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z_1000=z_1000.reshape(xx.shape)\n",
    "ax3 = plt.subplot(3,1,3, sharex = ax1)\n",
    "plt.pcolormesh(xx,yy,z_1000,alpha=0.1)\n",
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('Support Vector Machine_C=1000')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- C가 클수록 hardmargin (초평면이 빡빡하게 형성)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### kernel = 'polynomial'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### C = 0.001, 1, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_0001 = svm.SVC(kernel = 'poly', C = 0.001)\n",
    "svm_0001.fit(X_train, y_train)\n",
    "pred = svm_0001.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_1 = svm.SVC(kernel = 'poly', C = 1)\n",
    "svm_1.fit(X_train, y_train)\n",
    "pred = svm_1.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_1000 = svm.SVC(kernel = 'poly', C = 1000)\n",
    "svm_1000.fit(X_train, y_train)\n",
    "pred = svm_1000.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max=X_train.iloc[:,0].min()-1, X_train.iloc[:,0].max()+1\n",
    "y_min, y_max=X_train.iloc[:,1].min()-1,X_train.iloc[:,1].max()+1\n",
    "plot_unit=0.025\n",
    "xx,yy=np.meshgrid(np.arange(x_min, x_max, plot_unit), np.arange(y_min, y_max, plot_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,15))\n",
    "\n",
    "# C = 0.001\n",
    "z_0001=svm_0001.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z_0001=z_0001.reshape(xx.shape)\n",
    "ax1 = plt.subplot(3,1,1)\n",
    "plt.pcolormesh(xx,yy,z_0001,alpha=0.1)\n",
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('Support Vector Machine_C=0.001')\n",
    "\n",
    "# C = 1\n",
    "z_1=svm_1.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z_1=z_1.reshape(xx.shape)\n",
    "ax2 = plt.subplot(3,1,2, sharex = ax1)\n",
    "plt.pcolormesh(xx,yy,z_1,alpha=0.1)\n",
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('Support Vector Machine_C=1')\n",
    "\n",
    "# C = 1000\n",
    "z_1000=svm_1000.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z_1000=z_1000.reshape(xx.shape)\n",
    "ax3 = plt.subplot(3,1,3, sharex = ax1)\n",
    "plt.pcolormesh(xx,yy,z_1000,alpha=0.1)\n",
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('Support Vector Machine_C=1000')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C에 따른 정확도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.001,0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "accuracy = []\n",
    "from sklearn import svm\n",
    "for c in C:\n",
    "    svm_c = svm.SVC(kernel = 'poly', C = c)\n",
    "    svm_c.fit(X_train, y_train)\n",
    "    pred = svm_c.predict(X_test)\n",
    "    scores = accuracy_score(pred, y_test)\n",
    "    accuracy.append(scores)\n",
    "    \n",
    "plt.plot(C, accuracy)\n",
    "plt.xlabel('C')\n",
    "plt.xlim(-100, 10000)\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel = 'rbf'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### C =  0.1, 1, 100 \n",
    "###### gamma = 1, 10 , 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1_1 = svm.SVC(kernel = 'rbf', C =1 , gamma = 1)\n",
    "svm1_1.fit(X_train, y_train)\n",
    "pred = svm1_1.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1_10 = svm.SVC(kernel = 'rbf', C =1, gamma = 10)\n",
    "svm1_10.fit(X_train, y_train)\n",
    "pred = svm1_10.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1_100 = svm.SVC(kernel = 'rbf', C =1, gamma = 100)\n",
    "svm1_100.fit(X_train, y_train)\n",
    "pred = svm1_100.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_01 = svm.SVC(kernel = 'rbf', C = 0.1, gamma = 'auto')\n",
    "svm_01.fit(X_train, y_train)\n",
    "pred = svm_01.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_1 = svm.SVC(kernel = 'rbf', C = 1, gamma = 'auto')\n",
    "svm_1.fit(X_train, y_train)\n",
    "pred = svm_1.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_100 = svm.SVC(kernel = 'rbf', C = 100, gamma = 'auto')\n",
    "svm_100.fit(X_train, y_train)\n",
    "pred = svm_100.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max=X_train.iloc[:,0].min()-1, X_train.iloc[:,0].max()+1\n",
    "y_min, y_max=X_train.iloc[:,1].min()-1,X_train.iloc[:,1].max()+1\n",
    "plot_unit=0.025\n",
    "xx,yy=np.meshgrid(np.arange(x_min, x_max, plot_unit), np.arange(y_min, y_max, plot_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,15))\n",
    "\n",
    "# C = 1, gamma = 1 \n",
    "z_1_1=svm1_1.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z_1_1=z_1_1.reshape(xx.shape)\n",
    "ax1 = plt.subplot(3,2,1)\n",
    "plt.pcolormesh(xx,yy,z_1_1,alpha=0.1)\n",
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('Support Vector Machine_C=1_gamma=1')\n",
    "\n",
    "# C = 1, gamma = 10\n",
    "z_1_10=svm1_10.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z_1_10=z_1_10.reshape(xx.shape)\n",
    "ax2 = plt.subplot(3,2,3, sharex = ax1)\n",
    "plt.pcolormesh(xx,yy,z_1_10,alpha=0.1)\n",
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('Support Vector Machine_C=1_gamma=10')\n",
    "\n",
    "# C = 1, gamma = 1000\n",
    "z_1_100=svm1_100.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z_1_100=z_1_100.reshape(xx.shape)\n",
    "ax3 = plt.subplot(3,2,5, sharex = ax1)\n",
    "plt.pcolormesh(xx,yy,z_1_100,alpha=0.1)\n",
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('Support Vector Machine_C=1_gamma=100')\n",
    "\n",
    "# C = 0.1\n",
    "z_01=svm_01.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z_01=z_01.reshape(xx.shape)\n",
    "ax4 = plt.subplot(3,2,2, sharey = ax1)\n",
    "plt.pcolormesh(xx,yy,z_01,alpha=0.1)\n",
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('Support Vector Machine_C=0.1')\n",
    "\n",
    "# C = 1\n",
    "z_1=svm_1.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z_1=z_1.reshape(xx.shape)\n",
    "ax5 = plt.subplot(3,2,4, sharey = ax1)\n",
    "plt.pcolormesh(xx,yy,z_1,alpha=0.1)\n",
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('Support Vector Machine_C=1')\n",
    "\n",
    "# C = 100\n",
    "z_100=svm_100.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z_100=z_100.reshape(xx.shape)\n",
    "ax6 = plt.subplot(3,2,6, sharey = ax1)\n",
    "plt.pcolormesh(xx,yy,z_100,alpha=0.1)\n",
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.title('Support Vector Machine_C=100')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4차원 ( 시각화 불가능 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=iris_df.iloc[:, :-1]\n",
    "target=iris_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state= 111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = svm.SVC(kernel = 'linear', C = 1)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "pred = svm_linear.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2차원일 때 같은 조건 하 정확도가 0.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly = svm.SVC(kernel = 'poly', C = 1)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "pred = svm_poly.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- kernel 이나 C 같은 하이퍼파라미터는 튜닝을 거쳐 가장 좋은 성능을 띄는 모델을 찾아야 함 -> 하이퍼파라미터 튜닝"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- iris 데이터의 경우 feature의 단위가 cm로 통일되어 있기 때문에 유방암 진단 데이터셋 이용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유방암 진단 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "\n",
    "breast_cancer_df = pd.DataFrame(data = breast_cancer_data.data, columns = breast_cancer_data.feature_names)\n",
    "breast_cancer_df['target'] = breast_cancer_data.target\n",
    "\n",
    "data = breast_cancer_df.iloc[:,:-1]\n",
    "target = breast_cancer_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,3:10].describe()\n",
    "# mean area 과 다른 column 들의 max, min, mean 등 차이 큰 것 확인 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 음성 / 양성 구분짓는 이진분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state= 111)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "pred = knn.predict(X_test)\n",
    "accuracy_score(pred, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화, 표준화"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_standard = X_train.copy()\n",
    "X_test_standard = X_test.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "cols = X_train.columns\n",
    "\n",
    "X_train_standard[cols] = scaler.fit_transform(X_train_standard[cols]) \n",
    "X_test_standard[cols] = scaler.transform(X_test_standard[cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.iloc[5,:5].head()) \n",
    "print(X_train_standard.iloc[5,:5].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train.iloc[5,:5].describe())\n",
    "print(X_train_standard.iloc[5,:5].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train_standard, y_train)\n",
    "\n",
    "pred = knn.predict(X_test_standard)\n",
    "accuracy_score(pred, y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정규화 거치지 않았을 경우 0.93"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train_minmax = X_train.copy()\n",
    "X_test_minmax = X_test.copy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "cols = X_train.columns\n",
    "\n",
    "X_train_minmax[cols] = scaler.fit_transform(X_train_minmax[cols])\n",
    "X_test_minmax[cols] = scaler.transform(X_test_minmax[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_minmax.iloc[5,:5].head())\n",
    "print(X_train_minmax.iloc[:,:5].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train_minmax, y_train)\n",
    " \n",
    "pred = knn.predict(X_test_minmax)\n",
    "\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정규화 거치기 이전 0.93"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k 변화에 의한 accuracy 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = range(1,101)\n",
    "accuracy = []\n",
    "\n",
    "for k in k_list:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train_minmax, y_train)\n",
    "    pred = knn.predict(X_test_minmax)\n",
    "    score = accuracy_score(pred, y_test)\n",
    "    accuracy.append(score)\n",
    "    \n",
    "plt.plot(k_list, accuracy)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K가 커질수록 정확도가 하락한든 우하향 그래프\n",
    "- 적정한 K를 구해야함 (하이퍼파라미터 튜닝) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지금까지 설명드린 모델들은 간단한 분류를 위한 모델일 뿐입니다. 어떤 모델이 더 효과가 좋은지, 어떤 특성의 데이터에 어떤 모델을 써야하는 지와 하이퍼파라미터 튜닝하는 과정은 직접 프로젝트나 실습을 통해 비교해보고, 경험해보는 방향을 거치시는게 좋습니다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지도학습(분류) 과제"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC, 의사결정나무, KNN을 모델만 변경해서 분류 보고서를 출력해주세요. - 80점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# SVC 불러오기 \n",
    "from sklearn.___ import ___\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 \n",
    "# breast_cancer 데이터 사용합니다. \n",
    "\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "breast_cancer_df = pd.DataFrame(data = ______, columns = ________)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 설정\n",
    "breast_cancer_df['target'] = ________\n",
    "\n",
    "data = breast_cancer_df.iloc[__,___]\n",
    "target = breast_cancer_df['target']\n",
    "\n",
    "print(data)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(____, _____, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM 모델 생성\n",
    "model = SVC(kernel='____', C=____, gamma=____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "model.____(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "y_pred = model.____(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 보고서 출력 (분석 보고서 출력을 하는 코드는 classification_report입니다.)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 제출은 아래와 같이 classfication_report만 도출되도록 해주시면 됩니다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC 불러오기 \n",
    "from sklearn.___ import ___\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 데이터 불러오기 \n",
    "# breast_cancer 데이터 사용합니다. \n",
    "\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "breast_cancer_df = pd.DataFrame(data = ______, columns = ________)\n",
    "\n",
    "# target 설정\n",
    "breast_cancer_df['target'] = ________\n",
    "\n",
    "data = breast_cancer_df.iloc[__,___]\n",
    "target = breast_cancer_df['target']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(____, _____, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM 모델 생성\n",
    "model = SVC(kernel='____', C=____, gamma=____)\n",
    "\n",
    "# 모델 훈련\n",
    "model.____(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.____(X_test)\n",
    "\n",
    "# 분류 보고서 출력 (분석 보고서 출력을 하는 코드는 classification_report입니다.)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn 불러오기 \n",
    "from sklearn.___ import ___\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "breast_cancer_df = pd.DataFrame(data = ______, columns = ________)\n",
    "\n",
    "# target 설정\n",
    "breast_cancer_df['target'] = ________\n",
    "\n",
    "data = breast_cancer_df.iloc[__,___]\n",
    "target = breast_cancer_df['target']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(____, _____, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 이전 부분은 동일하니 위에서 복붙하셔도 됩니다. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "\n",
    "# KNN 모델 생성\n",
    "model = ____(*hyperparameter)\n",
    "\n",
    "# 모델 훈련\n",
    "model.____(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.____(X_test)\n",
    "\n",
    "# 분류 보고서 출력 (분석 보고서 출력을 하는 코드는 classification_report입니다.)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree 불러오기 \n",
    "from sklearn.___ import ___\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "breast_cancer_df = pd.DataFrame(data = ______, columns = ________)\n",
    "\n",
    "# target 설정\n",
    "breast_cancer_df['target'] = ________\n",
    "\n",
    "data = breast_cancer_df.iloc[__,___]\n",
    "target = breast_cancer_df['target']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(____, _____, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# 이전 부분은 동일하니 위에서 복붙하셔도 됩니다. \n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "\n",
    "# decision tree 모델 생성 (decision tree의 경우에 실습 영상에 나온 것 보다 많은 하이퍼파라미터가 있으니 궁금하신 분들은 구글에 검색해보시는 것을 추천드립니다.)\n",
    "model = ____(*hyperparameter)\n",
    "\n",
    "# 모델 훈련\n",
    "model.____(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.____(X_test)\n",
    "\n",
    "# 분류 보고서 출력 (분석 보고서 출력을 하는 코드는 classification_report입니다.)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 추가로 다른 분류 기법 검색 후에 분류 보고서 제출하시면 추가점수 드리겠습니다. - 20점  (RandomForest -10점, Gradient Boosting - 10점)\n",
    "- 모델을 적용하는 과정은 다 똑같으시니 랜덤포레스트, 그레디언트부스팅을 구글에 검색 후 \n",
    "    - 1. 라이브러리 이름\n",
    "    - 2. 모델 이름\n",
    "    - 3. 하이퍼파라미터 \n",
    "- 세 가지 종류를 확인해주시며 됩니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
